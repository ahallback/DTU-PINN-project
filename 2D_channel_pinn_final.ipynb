{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from DefineBoundaryFittedGeometries import define_geometry\n",
    "from ShowMeshesForBoundaryFittedGeometries import show_mesh_for_boundary_fitted_geometries\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.autograd import grad, functional\n",
    "from PIL import Image\n",
    "from channel_bend import *\n",
    "import torch.nn.init as init\n",
    "from softadapt import SoftAdapt, NormalizedSoftAdapt, LossWeightedSoftAdapt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose geometry\n",
    "geometry = 'M1'\n",
    "radius = 3\n",
    "_ = define_geometry(geometry, radius, show_geometry=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the meshes/points for each geometry. \n",
    "physics_xs, physics_ys = show_mesh_for_boundary_fitted_geometries(geometry, radius, print_on_off=False, plot=False)\n",
    "plt.scatter(physics_xs, physics_ys)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create array of all coordinates. \n",
    "\n",
    "physics_xys = np.zeros((physics_xs.shape[0], physics_xs.shape[1], 2))\n",
    "for i in range(physics_xs.shape[0]):\n",
    "    physics_xys[i] = np.column_stack((physics_xs[i], physics_ys[i]))\n",
    "\n",
    "physics_xys = np.reshape(physics_xys, (physics_xs.shape[0]*physics_xs.shape[1], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create inlet, outlet and walls arrays. \n",
    "\n",
    "# Define helper function\n",
    "def find_sub_list(sl,l):\n",
    "    sll=len(sl)\n",
    "    for ind in (i for i,e in enumerate(l) if e==sl[0]):\n",
    "        if l[ind:ind+sll]==sl:\n",
    "            return ind,ind+sll\n",
    "\n",
    "inlet_xys = np.zeros((physics_xs[-1].shape[0], 2))\n",
    "inlet_xys[:, 0] = physics_xs[-1]\n",
    "inlet_xys[:, 1] = physics_ys[-1]\n",
    "inlet_indices = find_sub_list(np.ndarray.tolist(inlet_xys), np.ndarray.tolist(physics_xys))\n",
    "\n",
    "outlet_xys = np.zeros((physics_xs[0].shape[0], 2))\n",
    "outlet_xys[:, 0] = physics_xs[0]\n",
    "outlet_xys[:, 1] = physics_ys[0]\n",
    "outlet_indices = find_sub_list(np.ndarray.tolist(outlet_xys), np.ndarray.tolist(physics_xys))\n",
    "\n",
    "right_wall_xs = physics_xs[:, 0]\n",
    "right_wall_ys = physics_ys[:, 0]\n",
    "\n",
    "left_wall_xs = physics_xs[:, -1]\n",
    "left_wall_ys = physics_ys[:, -1]\n",
    "\n",
    "left_wall_xys = np.zeros((left_wall_xs.shape[0], 2))\n",
    "left_wall_xys[:, 0] = left_wall_xs\n",
    "left_wall_xys[:, 1] = left_wall_ys\n",
    "\n",
    "right_wall_xys = np.zeros((right_wall_xs.shape[0], 2))\n",
    "right_wall_xys[:, 0] = right_wall_xs\n",
    "right_wall_xys[:, 1] = right_wall_ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(left_wall_xys[:, 0], left_wall_xys[:, 1])\n",
    "plt.scatter(right_wall_xys[:, 0], right_wall_xys[:, 1])\n",
    "plt.scatter(inlet_xys[1:-1, 0], inlet_xys[1:-1, 1])\n",
    "plt.scatter(outlet_xys[1:-1, 0], outlet_xys[1:-1, 1])\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate normal vectors for the boundary condition, pipe walls.\n",
    "gam1, _, gam2, _, gam3, _, gam4, _ = define_geometry(geometry, radius, show_geometry=False)\n",
    "\n",
    "# Choose functions. This changes with choice of geometry (alas).\n",
    "if geometry == 'M3':\n",
    "    left_wall_fct = gam3\n",
    "    right_wall_fct = gam1\n",
    "    inlet_fct = gam4\n",
    "    outlet_fct = gam2\n",
    "\n",
    "if geometry == 'M1':\n",
    "    left_wall_fct = gam2\n",
    "    right_wall_fct = gam4\n",
    "    inlet_fct = gam3\n",
    "    outlet_fct = gam1\n",
    "\n",
    "(\n",
    "    normal_vectors_left,\n",
    "    normal_vectors_right,\n",
    "    normal_vectors_inlet,\n",
    "    normal_vectors_outlet,\n",
    ") = get_normal_vectors(\n",
    "    left_wall_fct, right_wall_fct, inlet_fct, outlet_fct, nr_pts=28, show_normals=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_u = pd.read_csv('/home/ahal/GitRepos/DTU-PINN-project/data/Uvalues channel bend M1.csv', header=None )\n",
    "data_v = pd.read_csv('/home/ahal/GitRepos/DTU-PINN-project/data/Vvalues channel bend M1.csv', header=None )\n",
    "data_xys = pd.read_csv('/home/ahal/GitRepos/DTU-PINN-project/data/XYvalues channel bend M1.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_vel_u = data_u.to_numpy()\n",
    "exact_vel_v = data_v.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_xys = data_xys.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_xs = arr_xys[:, :28]\n",
    "data_ys = arr_xys[:, 28:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter = plt.scatter(data_xs, data_ys, c=exact_vel_u, vmin=-1.4, vmax=1.4)\n",
    "colorbar = plt.colorbar(scatter)\n",
    "plt.title(f\"Exact solution u\")\n",
    "plt.axis('equal')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "\n",
    "file = \"plots/channel_exact_u.png\"\n",
    "plt.savefig(file, bbox_inches='tight', pad_inches=0.1, dpi=100, facecolor=\"white\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter = plt.scatter(data_xs, data_ys, c=exact_vel_v, vmin=-1.4, vmax=1.4)\n",
    "colorbar = plt.colorbar(scatter)\n",
    "plt.title(f\"Exact solution v\")\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.axis('equal')\n",
    "\n",
    "file = \"plots/channel_exact_v.png\"\n",
    "plt.savefig(file, bbox_inches='tight', pad_inches=0.1, dpi=100, facecolor=\"white\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(f\"Numerical solution\")\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.axis('equal')\n",
    "plt.quiver(data_xs, data_ys, exact_vel_u, exact_vel_v)\n",
    "\n",
    "file = \"plots/channel_exact_quiver.png\"\n",
    "plt.savefig(file, bbox_inches='tight', pad_inches=0.1, dpi=100, facecolor=\"white\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define network architecture.\n",
    "\n",
    "class FullyConnected(nn.Module):\n",
    "  def __init__(self, n_inputs, n_hidden, n_outputs):\n",
    "    super().__init__()\n",
    "    self.input = nn.Sequential(\n",
    "      nn.Linear(n_inputs, n_hidden),\n",
    "      nn.Tanh(),\n",
    "    )\n",
    "    \n",
    "    self.hidden = nn.Sequential(\n",
    "      nn.Linear(n_hidden, n_hidden),\n",
    "      nn.Tanh(),\n",
    "      nn.Linear(n_hidden, n_hidden),\n",
    "      nn.Tanh(),\n",
    "      nn.Linear(n_hidden, n_hidden),\n",
    "      nn.Tanh(),\n",
    "    )\n",
    "\n",
    "    self.output = nn.Sequential(\n",
    "    nn.Linear(n_hidden, n_hidden),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(n_hidden, n_outputs),\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.input(x)\n",
    "    x = self.hidden(x)\n",
    "    x = self.output(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move all to GPU if available. \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training loop. \n",
    "# Include training data when available or just use physics loss. \n",
    "def train(model, \n",
    "          use_data, \n",
    "          learning_rate, \n",
    "          number_of_steps, \n",
    "          exact_vel_u, \n",
    "          exact_vel_v, \n",
    "          physics_xys, \n",
    "          inlet_xys, \n",
    "          outlet_xys, \n",
    "          right_wall_xys, \n",
    "          left_wall_xys, \n",
    "          normal_vectors_left, \n",
    "          normal_vectors_right\n",
    "         ):\n",
    "\n",
    "    # Define same \"random\" initialization og weights. \n",
    "    torch.manual_seed(123)\n",
    "    \n",
    "    # Data for M1 geoemtry\n",
    "    exact_vel_u_inlet = torch.tensor(exact_vel_u[-1], dtype=torch.float32).to(device)\n",
    "    exact_vel_v_inlet = torch.tensor(exact_vel_v[-1], dtype=torch.float32).to(device)\n",
    "    exact_vel_u_outlet = torch.tensor(exact_vel_u[0], dtype=torch.float32).to(device)\n",
    "    exact_vel_v_outlet = torch.tensor(exact_vel_v[0], dtype=torch.float32).to(device)\n",
    "    \n",
    "    \n",
    "    # Define loss weighting. \n",
    "    pde_weight = 1e-2\n",
    "    boundary_weight = 1.0\n",
    "    data_weight = 1.0\n",
    "    \n",
    "    # Convert everything to tensors. \n",
    "    physics_xys_tensor = torch.tensor(physics_xys, dtype=torch.float32).requires_grad_(True).to(device)\n",
    "    right_wall_xys_tensor = torch.tensor(right_wall_xys, dtype=torch.float32).requires_grad_(True).to(device)\n",
    "    left_wall_xys_tensor = torch.tensor(left_wall_xys, dtype=torch.float32).requires_grad_(True).to(device)\n",
    "    normal_vectors_left_tensor = torch.tensor(normal_vectors_left, dtype=torch.float32).to(device)\n",
    "    normal_vectors_right_tensor = torch.tensor(normal_vectors_right, dtype=torch.float32).to(device)  \n",
    "    \n",
    "    # Define model.\n",
    "    model = model.to(device)\n",
    "    optimizer2 = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "    scheduler = StepLR(optimizer2, step_size=10000, gamma=0.95)\n",
    "    \n",
    "    loss_list = []\n",
    "    \n",
    "    # SoftAdapt.\n",
    "    softadapt_object = SoftAdapt(beta=1)\n",
    "    boundary_loss_list = []\n",
    "    pde_loss_list = []\n",
    "    data_loss_list = []\n",
    "    adapt_weights = torch.tensor([boundary_weight, pde_weight, data_weight]).to(device)\n",
    "    \n",
    "    \n",
    "    for i in range(number_of_steps + 1):\n",
    "      optimizer2.zero_grad()\n",
    "    \n",
    "      # get model's results.\n",
    "      physics_pred_fs = model(physics_xys_tensor)\n",
    "      grad_f = gradient(physics_pred_fs, physics_xys_tensor)\n",
    "    \n",
    "      df_dx = grad_f[:, 0]\n",
    "      df_dy = grad_f[:, 1]\n",
    "    \n",
    "      # Data loss\n",
    "      if use_data:\n",
    "          exact_df_dx = torch.tensor(exact_vel_u.flatten(), dtype=torch.float32).to(device)\n",
    "          exact_df_dy = torch.tensor(exact_vel_v.flatten(), dtype=torch.float32).to(device)\n",
    "          data_loss = torch.mean((df_dx - exact_df_dx)**2) + torch.mean((df_dy - exact_df_dy)**2)\n",
    "      else:\n",
    "          data_loss = 0\n",
    "    \n",
    "      # Physics loss\n",
    "      d2f_dx2 = gradient(df_dx, physics_xys_tensor)[:, 0]\n",
    "      d2f_dy2 = gradient(df_dy, physics_xys_tensor)[:, 1]\n",
    "    \n",
    "      # Define PDE residual. \n",
    "      residual_laplace = (d2f_dx2 + d2f_dy2)**2\n",
    "      pde_residual_loss = torch.mean(residual_laplace)\n",
    "      \n",
    "      # Inlet loss\n",
    "      inlet_grad_values = grad_f[inlet_indices[0]:inlet_indices[1], :]\n",
    "    \n",
    "      df_dx_inlet = inlet_grad_values[:, 0]\n",
    "      df_dy_inlet = inlet_grad_values[:, 1]\n",
    "    \n",
    "      inlet_loss = torch.mean((df_dx_inlet - exact_vel_u_inlet)**2) + torch.mean((df_dy_inlet - exact_vel_v_inlet)**2)\n",
    "      \n",
    "      # Outlet loss\n",
    "      outlet_grad_values = grad_f[outlet_indices[0]:outlet_indices[1], :]\n",
    "    \n",
    "      df_dx_outlet = outlet_grad_values[:, 0]\n",
    "      df_dy_outlet = outlet_grad_values[:, 1]\n",
    "    \n",
    "      outlet_loss = torch.mean((df_dx_outlet - exact_vel_u_outlet)**2) + torch.mean((df_dy_outlet - exact_vel_v_outlet)**2)\n",
    "    \n",
    "      # Boundary condition on walls. Use zero-flux. \n",
    "      right_wall_values = model(right_wall_xys_tensor)\n",
    "      left_wall_values = model(left_wall_xys_tensor)\n",
    "    \n",
    "      right_wall_grad = grad_f[::28, :]\n",
    "      left_wall_grad = grad_f[27::28, :]\n",
    "    \n",
    "      flux_left_wall = left_wall_grad[:, 0] * normal_vectors_left_tensor[:, 0] + left_wall_grad[:, 1] * normal_vectors_left_tensor[:, 1]\n",
    "      flux_right_wall = right_wall_grad[:, 0]  * normal_vectors_right_tensor[:, 0] + right_wall_grad[:, 1] * normal_vectors_right_tensor[:, 1]\n",
    "      \n",
    "      left_wall_loss = torch.mean(flux_left_wall**2)\n",
    "      right_wall_loss = torch.mean(flux_right_wall**2)\n",
    "    \n",
    "      # Compute total boundary loss.\n",
    "      boundary_loss = inlet_loss + outlet_loss + left_wall_loss + right_wall_loss \n",
    "    \n",
    "      # Compute total physics loss.\n",
    "      physics_loss = pde_residual_loss\n",
    "    \n",
    "      # SoftAdapt. Keep track of each loss component\n",
    "      boundary_loss_list.append(boundary_loss)\n",
    "      pde_loss_list.append(pde_residual_loss)\n",
    "      data_loss_list.append(data_loss)\n",
    "    \n",
    "      # SoftAdapt. Update weights for every fifth step\n",
    "      if i % 5 == 0 and i != 0:\n",
    "        adapt_weights = softadapt_object.get_component_weights(\n",
    "          torch.tensor(boundary_loss_list),\n",
    "          torch.tensor(pde_loss_list),\n",
    "          torch.tensor(data_loss_list),\n",
    "          verbose=False,\n",
    "        )\n",
    "    \n",
    "        boundary_loss_list = []\n",
    "        pde_loss_list = []\n",
    "        data_loss_list = []\n",
    "      \n",
    "      loss =  adapt_weights[0] * boundary_loss + adapt_weights[1] * physics_loss + adapt_weights[2]*data_loss \n",
    "      \n",
    "      loss_list.append(loss)\n",
    "    \n",
    "      loss.backward()\n",
    "      optimizer2.step()\n",
    "      scheduler.step()\n",
    "      \n",
    "    \n",
    "      # Visualize.\n",
    "      if i % 5000 == 0 and i != 0:\n",
    "        print(f'Step: {i}')\n",
    "        print(f'PDE loss, boundary loss, data loss: {pde_residual_loss, boundary_loss, data_loss}')\n",
    "    \n",
    "        # Show PINNs values. \n",
    "        # Detach PIIns values. \n",
    "        values_f = physics_pred_fs.cpu().detach().numpy()\n",
    "        values_dx = df_dx.cpu().detach().numpy()\n",
    "        diff_dx = values_dx - exact_vel_u.flatten()\n",
    "        values_dy = df_dy.cpu().detach().numpy()\n",
    "        diff_dy = values_dy - exact_vel_v.flatten()\n",
    "        values_laplace = residual_laplace.cpu().detach().numpy()\n",
    "    \n",
    "        # Plots\n",
    "        scatter = plt.scatter(physics_xys[:, 0], physics_xys[:, 1], c=diff_dx, vmin=-0.2, vmax=0.2)\n",
    "        colorbar = plt.colorbar(scatter)\n",
    "        plt.title(f\"PINN u error at step {i}\")\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('y')\n",
    "        plt.axis('equal')\n",
    "        \n",
    "        if i % number_of_steps == 0:\n",
    "            file = \"plots/channel_pred_u_wd.png\"\n",
    "            plt.savefig(file, bbox_inches='tight', pad_inches=0.1, dpi=100, facecolor=\"white\")\n",
    "          \n",
    "        plt.show()\n",
    "        \n",
    "        scatter = plt.scatter(physics_xys[:, 0], physics_xys[:, 1], c=diff_dy, vmin=-0.2, vmax=0.2)\n",
    "        colorbar = plt.colorbar(scatter)\n",
    "        plt.title(f\"PINN v error at step {i}\")\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('y')\n",
    "        plt.axis('equal')\n",
    "    \n",
    "        if i % number_of_steps == 0:\n",
    "            file = \"plots/channel_pred_v_wd.png\"\n",
    "            plt.savefig(file, bbox_inches='tight', pad_inches=0.1, dpi=100, facecolor=\"white\")\n",
    "             \n",
    "        plt.show()\n",
    "    \n",
    "        scatter = plt.scatter(physics_xys[:, 0], physics_xys[:, 1], c=values_laplace, cmap='RdYlBu_r', edgecolors='k', linewidths=0.5, vmin=0.0, vmax=0.02)\n",
    "        plt.colorbar(scatter)\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('y')\n",
    "        plt.axis('equal')\n",
    "        plt.title('Magnitude of Laplace residual')\n",
    "    \n",
    "        if i % number_of_steps == 0:\n",
    "            file = \"plots/channel_pred_laplace_wd.png\"\n",
    "            plt.savefig(file, bbox_inches='tight', pad_inches=0.1, dpi=100, facecolor=\"white\")\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "        if i % number_of_steps == 0:\n",
    "            return loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shared parameters\n",
    "number_of_steps = 10000\n",
    "learning_rate = 1e-3\n",
    "model = FullyConnected(2, 64, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train without data\n",
    "use_data = False\n",
    "loss = train(model, use_data, learning_rate, number_of_steps, exact_vel_u, exact_vel_v, physics_xys, inlet_xys, outlet_xys, right_wall_xys, left_wall_xys, normal_vectors_left, normal_vectors_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with data\n",
    "use_data = True\n",
    "loss_with_data = train(model, use_data, learning_rate, number_of_steps, exact_vel_u, exact_vel_v, physics_xys, inlet_xys, outlet_xys, right_wall_xys, left_wall_xys, normal_vectors_left, normal_vectors_right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list_detached = []\n",
    "for tensor in loss:\n",
    "    loss_list_detached.append(tensor.cpu().detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list_detached_with_data = []\n",
    "for tensor in loss_with_data:\n",
    "    loss_list_detached_with_data.append(tensor.cpu().detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print full loss\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(loss_list_detached, label = 'Without data')\n",
    "plt.plot(loss_list_detached_with_data, label = 'With data')\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Training step')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim((0.0,0.05))\n",
    "plt.legend()\n",
    "\n",
    "file = \"plots/channel_loss.png\"\n",
    "plt.savefig(file, bbox_inches='tight', pad_inches=0.1, dpi=100, facecolor=\"white\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print loss for last 5000 steps\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(loss_list_detached, label = 'Without data')\n",
    "plt.plot(loss_list_detached_with_data, label = 'With data')\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Training step')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim((0.0,0.02))\n",
    "plt.xlim((number_of_steps - 5000,number_of_steps + 300))\n",
    "plt.legend()\n",
    "\n",
    "file = \"plots/channel_loss_end.png\"\n",
    "plt.savefig(file, bbox_inches='tight', pad_inches=0.1, dpi=100, facecolor=\"white\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
